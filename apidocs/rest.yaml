---
swagger: '2.0'
info:
  version: 0.2.0
  title: VMX REST API
  description: |
    **This is the VMX REST API 
      which lets you manage multiple VMX sessions**

    Let's start VMX locally on port 3000 on our machine.

    **On a Mac**
    ```
    cd /Applications/VMX.app/Contents/MacOS/
    ./run.sh
    ```

    **On Linux**
    ```
    cd ~/vmx-docker-manager
    ./vmx start 3000
    ```
      
  contact:
    name: vision.ai API team
    url: https://api.vision.ai    

host: localhost:3000
schemes:
  - http
paths:
  /session:
    post:
      tags: 
        - session management
      summary: Create New Session
      description: "Create a new session. You can specify an empty json payload to get a randomly generated session id, or you can provide the session id you want via the `id` field."
      
      parameters:
        - in: body
          name: body
          description: The new id
          schema:
            $ref: "#/definitions/CreateSessionInput"
      responses:
        200:
          description: OK
          schema:
           properties:
            data:
              type: array
              items:
                $ref: '#/definitions/ModelSummary'
        500:
          description: "Cannot create session (id contains illegal characters)"

    get:
      tags: 
        - session management
      summary: List sessions
      description: "Lists the active VMXworker sessions which are registered by VMX"
    
      responses:
        200:
          description: OK
          schema:
           properties:
            data:
              type: array
              items:
                $ref: '#/definitions/SessionSummary'
        400:
          description: Problem Loading Model(s)

  /session/{sessionId}:
    get:
      tags: 
        - session management
      parameters:
        - name: sessionId
          in: path
          type: string
          description: ID of the session
          required: true
      summary: "Get session info"
      responses:
        400:
          description: "Not defined"
    delete:
      tags:
        - session management
      parameters:
        - name: sessionId
          in: path
          type: string
          description: ID of the session
          required: true
      summary: "Delete current session from VMX"
      responses:
        200:
          description: "OK"  
        404:
          description: Session id not found

  /save_model:
    post:
      tags: 
        - model_library
      summary: Save currently loaded model
      description: "Save the currently loaded model into the `${VMX_DIR}` directory. Allows for renaming the model as well as generating a new UUID for the saved model. If the currently loaded model is a bundle, then a new UUID cannot be generated since bundle UUIDs are determined from the component UUIDs. Will not allow save operation when `config.read_only` is set to `true`."
      parameters:
        - in: body
          name: body
          description: Information about the saved model
          required: true
          schema:
            $ref: "#/definitions/SaveModelInput"
      responses:
        200:
          description: OK
          schema:
           properties:
            data:
              properties:
                model:
                  $ref: "#/definitions/ModelSummary"
                full_MB:
                  type: number
                  description: "The size of the full model in Megabytes"
                compiled_MB:
                  type: number
                  description: "The size of the compiled model in Megabytes"
        400:
          description: Problem saving model

  /create_model:
    post:
      tags: 
        - detection
      summary: Create a new model
      description: "Create a new model given a dataset, a model name, a pretrained file, and detection/creation parameters. 
  
      
        1.) Will look for the pretrained file inside the `data` directory specified in `config.json`, 
  
        
        2.) If not present, will look for the pretrained file in the `/VMXdata/` directory (and copy it over to your `data` directory) 
  
        
        3.) Will download the file from `https://files.vision.ai/vmx/pretrained/` (as long as `config.allow_urls` is set to true) into your `data` directory.
      
        VMXserver comes with two pretrained files. To get a listing of available pretrained files, run:
        
        `curl https://files.vision.ai/vmx/pretrained/MD5SUMS.json`
          
        "
      parameters:
        - in: body
          name: body
          description: Model Creation payload
          required: true
          schema:
            $ref: "#/definitions/CreateModelInput"
      responses:
        200:
          description: OK
          schema:
           properties:
            data:
              properties:
                model:
                  $ref: "#/definitions/ModelSummary"
                objectives:
                  $ref: "#/definitions/Objectives"
        400:
          description: Unable to create model. Either `config.read_only` is set to `false` (see set_config) or there was a problem with your payload. 

  /edit_model:
    post:
      tags: 
        - detection
      summary: Edit model
      description: "Edit/show the positive examples inside the model. Can be used to show image crops of the positives/negatives, swap examples, or remove examples."
      parameters:
        - in: body
          name: body
          description: Edit Model Payload
          required: true
          schema:
            $ref: "#/definitions/EditModelInput"
      responses:
        200:
          description: OK
          schema:
           properties:
            data:
              properties:
                images:
                  type: array
                  items:
                    $ref: "#/definitions/Image"
                objectives:
                  $ref: "#/definitions/Objectives"
        400:
          description: Cannot edit model

  /process_image:
    post:
      tags: 
        - detection
      summary: Process Image by applying current model. 
      description: "Process Image by applying current model. Even though the input must be an array of images, for detection and learning is only performed on the first image. Allows the model to grow in size by enabling `learning_mode`. Will not allow `learning_mode` when `config.read_only` is set to `true`."
      parameters:
        - in: body
          name: body
          description: Process Image Payload
          required: true
          schema:
            $ref: "#/definitions/ProcessImageInput"
      responses:
        200:
          description: OK
          schema:
           properties:
            data:
              properties:
                model:
                  $ref: "#/definitions/ModelSummary"
                objects:
                  type: array
                  items:
                    $ref: "#/definitions/Object"
        400:
          description: Cannot process image

  /get_config:
    get:
      tags: 
        - settings
      summary: Get the configuration object
      description: "Get the configuration object"
      responses:
        200:
          description: OK
          schema:
            properties:
              data:
                $ref: "#/definitions/Config"

  /get_params:
    get:
      tags: 
        - settings
      summary: Get the detection params
      description: "Get the detection params"
      responses:
        200:
          description: OK
          schema:
            properties:
              data:
                $ref: "#/definitions/Params"

  /set_config:
    post:
      tags: 
        - settings
      summary: Set the configuration object
      description: "Set the configuration object"
      parameters:
        - in: body
          name: body
          description: Input Data Set
          schema:
            $ref: "#/definitions/Config"
      responses:
        200:
          description: OK
          schema:
            properties:
              data:
                $ref: "#/definitions/Config"

  /exit:
    post:
      tags: 
        - settings
      summary: Exit session
      description: "Shut down the session. Be warned that you **must save your model** if you made edits and don't want to lose changes to your model."
      responses:
        200:
          description: OK
        400:
          description: Cannot shutdown (`config.read_only` is `true`)


definitions:
  LoadModelInput:
    required:
      - uuids
    properties:
      compiled:
        type: boolean
        example: false
        description: "If enabled, will load the model in compiled mode. Compiled models are not editable, but they use less memory and are a bit faster for detection. When loading a collection of models, they will be in compiled mode. There is no way to load a collection of uncompiled models. Only one model can be uncompiled at a time."
      uuids:
        type: array
        description: "A collection of UUIDs to load"
        items:
          type: string

  SaveModelInput:
    properties:
      name:
        type: string
        example: left_hand_up
        default: ""
        description: "If present and non-empty, will assign the new name to the model.  This will not change the UUID, just the `name` field that show up in listing models and assigning tags to detection boxes"
      new_uuid:
        type: boolean
        example: false
        default: false
        description: "If true, will assign a new UUID, effectively copying the model."
        
  ModelSummary:
    properties:
      name:
        type: string
        example: "tom's hand"
        description: "A human readable model name"
      uuid:
        type: string
        example: "17b86476-d430-4ecb-8185-aff17c18321c"
        description: "The unique identifier for the model. Model bundles (collections of models) do not have hyphens in the UUID, and individual models have UUIDs in standard 36 character format"
      meta:
        type: string
        description: "Extra meta information about the model. Bundles will use comma separated names of individual models for the meta tag."
      history:
        description: "The name of the pretrained file used to generate the model. Will be an array of the individual models if model is a bundle."
        type: array
        items:
          type: string
      compiled:
        type: boolean
        description: "Whether the model is compiled or not"
      version:
        type: string
        description: "The version of VMX which generated this model"
      image:
        type: string
        description: "image description (dataurl or image relative to vmx_dir)"
        example: "models/53255aee-f032-4df1-a61e-1502f1df33d4/image.jpg"
      size:
        type: array
        items:
          type: integer
        description: "The size of the model"
      num_pos:
        type: integer
        description: "The number of positive examples in the model"
      num_neg:
        type: integer
        description: "The number of negative examples in the model"
      start_time:
        type: string
        description: "Model creation time"
      end_time:
        type: string
        description: "Last image/datapoint time"  
  CreateModelInput:
    required:
      - name
      - pretrained
      - images
      - params
    properties:
      name:
        type: string
      pretrained:
        type: string
        description: "The pretrained file to use for model creation. Will default to the `pretrained` filed inside the `config.json` file next to the binary."
        
      images:
        type: array 
        items:
          $ref: '#/definitions/Image'
      params:
        $ref: '#/definitions/Params'

  
  Image:
    required:
      - image
    properties:
      image:
        type: string
        example: "http://sdfsdf.com/image.jpg"
        description: "The base64 encoded image or URL pointing to image, works with base64 type prefix or not"
      objects:
        type: array
        items:
          $ref: '#/definitions/Object'
  
  Object:
    required:
     - name
     - bb
    properties:
      name:
        type: string
        example: "left_hand"
        description: "The object's human readable name"
      bb:
        type: array
        items:
          type: number
        description: "The object's bounding box (4 numbers)"
      score:
        type: number
        description: "optional score associated with example"
      data:
        description: "Extra data stored with the example"
        type: array
        items:
          type: number
      id:
        type: integer
        description: "optional id used to index examples when using edit_model"
      class_label:
        type: integer
        description: "optional class_label used to denote positives (+1), negatives (-1), or remove example (0)"
        
        
  Params:
    properties:
      detect_max_overlap:
        type: number
        default: 0.3
        description: "The non-maximum suppression threshold which will remove redundant (highly-overlapping windows).  This number ranges from [0,1] and 0 will not allow any returned detectections to overlap, while a 1.0 will keep all detection windows."
        minimum: 0.0
        maximum: 1.0
      detect_add_flip:
        type: boolean
        default: false
        description: "If enabled, will perform detection on left-right flip of input image. Detection then takes twice as long, but only one image needs to be sent to the server."
      levels_per_octave:
        type: integer
        default: 10
        minimum: 1
        maximum: 20
        description: "The levels per octave parameters describes how many different levels we use for object detection.  An octave is a halving of the original image, so 10 levels per octave means we will be looking at 10 different images sizes betwen the original and the halved image. Must be between 1 and 20. Lower will make detection faster, but be careful for scale-dependent blind spots."
      max_windows:
        type: integer
        default: 100
        minimum: 0
        description: "The maximum number of raw detection windows to consider before applying non-maximum suppression.  The final number of detections will always be smaller than max_windows as non-maximum suppression will likely remove some.  The detector becomes really fast for max_windows=0, but it has better performance for large
          max_windows values."
      max_image_size:
        type: integer
        default: 320
        minimum: 0
        description: "The maximum input image size (in number of pixels for either width or height).  You are free to send a larger image, but it will be resized to this size if the input is larger. Resizing maintains the aspect ratio, and makes sure that the maximum dimension is within this limit."
        
      learn_mode:
        type: boolean
        default: false
        description: "If enabled, go into learn mode."
        
      learn_iterations:
        type: integer
        default: 10
        minimum: 0
        description: "The number of learning iterations after each successful update while processing images in \"learn mode\"."
        
      learn_max_positives:
        type: integer
        default: 1
        minimum: 0
        description: "The maximum number of positives which can be extracted from a single image during one step of `learn_mode`.  NOTE that to be considered a positive, then score must be above learn_threshold. You can make the detector treat everything as negatives by setting learn_max_positives to 0, and the learn_threshold to a really low value like -1.  You can make the detector treat all detections above 0 as positives by setting learn_max_positives to something large like 100 and the learn_threshold to 0.  NOTE: If you feed VMX an image with many true positives but learn_max_positives is set to 1, then only the highest scoring detection will be treated as a positive and the remaining detections as negatives."
        
      learn_threshold:
        type: number
        default: 0
        description: "Object detections scoring above this threshold will be considered as positives while in `learn mode`. At most `learn_max_positives` will be treated as positives."
        
      cell_size:
        type: integer
        default: 4
        minimum: 2
        description: "The spatial cell size (in pixels) used to analyze the input image.  This is the size of the regions for which statistical computations are performed."
      
      initialize_max_cells: 
        type: integer
        default: 10
        minimum: 1
        description: "The maximum template dimension (measured in cells) used during initialization. Model sizes are reported as #cells x #cells. This parameter makes sure that you don't get very large cell sizes for model creation. If you decide to create a model with initialize_max_cells set to a small value like 4, you might get models that are 2x4, 4x1, etc.  They will be really fast, but much coarser than your typical 8x10 models."
        
      initialize_add_flip:
        type: boolean
        default: false
        description: "If enabled, model creation will add left-right flips of positives to generate 2X training data, then select the best of each flip."
        
      train_max_positives:
        type: integer
        default: 1000
        minimum: 1
        description: "The maximum number of positives inside the learned model.  VMX automatically adjust the number of positives (by dropping the least useful examples) when a larger number is reached when using learning mode."
        
      train_max_negatives:
        type: integer
        default: 2000
        minimum: 1
        description: "The maximum number of positives inside the learned model.  VMX automatically adjust the number of positives (by dropping the least useful examples) when a larger number is reached when using learning mode."
        
      crop_radius:
        type: integer
        default: 80
        description: "The number of pixels around the object of interest to be used in crop mode.  This greatly improves the speed of the detector as fewer regions need to be analyzed. NOTE: this is only used inside the VMX GUI (aka vmxAppBuilder) but stored inside VMX as a convenience."
        
      display_threshold:
        type: number
        default: 0
        description: "When using process_image, drop all detections below this threshold. Mac Only: Objects scoring above this threshold will be rendered on the screen when config.display_images is enabled."
        
      jpeg_quality:
        type: number
        default: 1
        description: "The JPEG Quality factor controls the size (in MB) of the image but creates compression artifacts. Note: this is only used inside the VMX GUI (aka vmxAppBuilder) but stored inside the model as a convenience."

  Settings:
    required:
      - max_positives
      - max_negatives
    properties:
      learn_iterations:
        type: integer
        description: "The number of learning updates"
        minimum: 0
        maximum: 1000
        default: 0
      max_positives:
        type: integer
        description: "The maximum number of positives to show"
        minimum: 0
        default: 20
      max_negatives:
        type: integer
        description: "The maximum number of negatives to show"
        minimum: 0
        default: 20
      positives_order:
        type: integer
        description: "The ordering on the positives. 1 is ascending order, -1 is descending order."
        default: 1
      negatives_order:
        type: integer
        description: "The ordering on the negatives. 1 is ascending order, -1 is descending order."
        default: -1
      image_size:
        type: integer
        description: "The size of the resulting image crops (expressed as size of maximum dimension). A value of 0 will not even generate resulting images"
        default: 100
        minimum: 0
        maximum: 1000
      pad_scale:
        type: number
        minimum: 0
        maximum: 2
        default: 1
        description: "How much to pad around each exemplar, useful for showing extra context around an object. 1 is the defalut which shows a tight image crop around the exemplar. 0 will not even show images, and 2 will show 200% of the original exemplar."

  Change:
    required:
      - id
      - class_label
    properties:
      image:
        type: string  
      score:
        type: number
      class_label:
        type: integer
        description: "Should be -1 for negative, +1 for postive, and 0 for remove_me"
      id:
        type: integer
        description: "The unique identifier for the exemplar"
      time:
        type: string
        description: "Time associated with datapoint"
      data:
        type: array
        items: 
          type: number
          
  SessionSummary:
    properties:
      model:
        description: "The model summary"
        $ref: '#/definitions/ModelSummary'
      id:
        type: string
        description: "The session id"
  
  EditModelInput:
    required:
      - changes
      - settings
    properties:
      changes:
        type: array
        items:
          $ref: '#/definitions/Change'
      settings:
        $ref: '#/definitions/Settings'
        
  ProcessImageInput:
    required:
      - images
    properties:
      images:
        type: array 
        items:
          $ref: '#/definitions/Image'
      params:
        $ref: '#/definitions/Params'
      name:
        type: string
        default: ""
        description: "The name of the detections we want. Useful if you have a session loaded with 100s of models, but you just want detections of a certain category. NOTE: currently not implemented"
        
  Config:
    properties:
      pretrained:
        type: string
        description: "The default pretrained file used for model creation when the `pretrained` field is empty inside `create_model`."
      log_images:
        type: boolean
        description: "Whether to log full images or grep them out in the JSON-based session log. Both `create_model` and `process_image` operations contain dataURLs in the payload, so if you are going to be sharing logs, it is best practice to remove these dataURLs. The `edit_model` operation will contain dataURLs in the output.  If `log_images` is enabled, the dataURLs are replaced with the string \"IMAGE\""
        default: false
      log_memory:
        type: boolean
        default: false
        description: "If enabled, will add `memory` field to each line of the JSON log. This is useful for debugging, but should not be used in production."  
      display_images:
        type: boolean
        default: false
        description: "If enabled, will render images and bounding boxes on your Desktop.  Only works on `Mac OS X`."
      allow_urls:
        type: boolean
        default: true
        description: "If enabled, will allow input images (for both `create_model` and `process_image` requests) to be URLs.  This is a very handy feature, but it is advised to turn this feature off for production."
      read_only:
        type: boolean
        default: false
        description: "If enabled, will only allow read-only operations. This means `create_model`, `edit_model`, and `exit` won't work."
        
  Objectives:
    properties:
      obj:
        type: number
        description: "The objective function value (with regularization terms added). The lower the better."
      obj_raw:
        type: number
        description: "The objective function value (without regularization terms added). The lower the better."
        
        
        
  CreateSessionInput:
    properties:
      id:
        type: string
        default: ""
        description: "The desired session id, if not specified, will autogenerate one for you. The string must be alphanumeric, at least length 1, and the only valid non-alphanumeric character is the dash"
      