{"swagger":"2.0","schemes":["http"],"host":"localhost:3000","info":{"contact":{"url":"https://api.vision.ai","name":"vision.ai API team"},"version":"0.2.0","title":"VMX REST API","description":"**This is the VMX REST API \n  which lets you manage multiple VMX sessions**\n\nLet's start VMX locally on port 3000 on our machine.\n\n**On a Mac**\n```\ncd /Applications/VMX.app/Contents/MacOS/\n./run.sh\n```\n\n**On Linux**\n```\ncd ~/vmx-docker-manager\n./vmx start 3000\n```\n  \n"},"definitions":{"Objectives":{"properties":{"obj_raw":{"type":"number","description":"The objective function value (without regularization terms added). The lower the better."},"obj":{"type":"number","description":"The objective function value (with regularization terms added). The lower the better."}}},"CreateSessionInput":{"properties":{"id":{"default":"","type":"string","description":"The desired session id, if not specified, will autogenerate one for you. The string must be alphanumeric, at least length 1, and the only valid non-alphanumeric character is the dash"}}},"LoadModelInput":{"required":["uuids"],"properties":{"compiled":{"example":false,"type":"boolean","description":"If enabled, will load the model in compiled mode. Compiled models are not editable, but they use less memory and are a bit faster for detection. When loading a collection of models, they will be in compiled mode. There is no way to load a collection of uncompiled models. Only one model can be uncompiled at a time."},"uuids":{"items":{"type":"string"},"type":"array","description":"A collection of UUIDs to load"}}},"Image":{"required":["image"],"properties":{"image":{"example":"http://sdfsdf.com/image.jpg","type":"string","description":"The base64 encoded image or URL pointing to image, works with base64 type prefix or not"},"objects":{"items":{"$ref":"#/definitions/Object"},"type":"array"}}},"ProcessImageInput":{"required":["images"],"properties":{"images":{"items":{"$ref":"#/definitions/Image"},"type":"array"},"params":{"$ref":"#/definitions/Params"},"name":{"default":"","type":"string","description":"The name of the detections we want. Useful if you have a session loaded with 100s of models, but you just want detections of a certain category. NOTE: currently not implemented"}}},"Config":{"properties":{"pretrained":{"type":"string","description":"The default pretrained file used for model creation when the `pretrained` field is empty inside `create_model`."},"log_images":{"default":false,"type":"boolean","description":"Whether to log full images or grep them out in the JSON-based session log. Both `create_model` and `process_image` operations contain dataURLs in the payload, so if you are going to be sharing logs, it is best practice to remove these dataURLs. The `edit_model` operation will contain dataURLs in the output.  If `log_images` is enabled, the dataURLs are replaced with the string \"IMAGE\""},"log_memory":{"default":false,"type":"boolean","description":"If enabled, will add `memory` field to each line of the JSON log. This is useful for debugging, but should not be used in production."},"allow_urls":{"default":true,"type":"boolean","description":"If enabled, will allow input images (for both `create_model` and `process_image` requests) to be URLs.  This is a very handy feature, but it is advised to turn this feature off for production."},"display_images":{"default":false,"type":"boolean","description":"If enabled, will render images and bounding boxes on your Desktop.  Only works on `Mac OS X`."},"read_only":{"default":false,"type":"boolean","description":"If enabled, will only allow read-only operations. This means `create_model`, `edit_model`, and `exit` won't work."}}},"SessionSummary":{"properties":{"model":{"$ref":"#/definitions/ModelSummary","description":"The model summary"},"id":{"type":"string","description":"The session id"}}},"CreateModelInput":{"required":["name","pretrained","images","params"],"properties":{"images":{"items":{"$ref":"#/definitions/Image"},"type":"array"},"pretrained":{"type":"string","description":"The pretrained file to use for model creation. Will default to the `pretrained` filed inside the `config.json` file next to the binary."},"params":{"$ref":"#/definitions/Params"},"name":{"type":"string"}}},"Settings":{"required":["max_positives","max_negatives"],"properties":{"learn_iterations":{"maximum":1000,"default":0,"minimum":0,"type":"integer","description":"The number of learning updates"},"pad_scale":{"maximum":2,"default":1,"minimum":0,"type":"number","description":"How much to pad around each exemplar, useful for showing extra context around an object. 1 is the defalut which shows a tight image crop around the exemplar. 0 will not even show images, and 2 will show 200% of the original exemplar."},"image_size":{"maximum":1000,"default":100,"minimum":0,"type":"integer","description":"The size of the resulting image crops (expressed as size of maximum dimension). A value of 0 will not even generate resulting images"},"max_negatives":{"default":20,"minimum":0,"type":"integer","description":"The maximum number of negatives to show"},"negatives_order":{"default":-1,"type":"integer","description":"The ordering on the negatives. 1 is ascending order, -1 is descending order."},"max_positives":{"default":20,"minimum":0,"type":"integer","description":"The maximum number of positives to show"},"positives_order":{"default":1,"type":"integer","description":"The ordering on the positives. 1 is ascending order, -1 is descending order."}}},"SaveModelInput":{"properties":{"name":{"example":"left_hand_up","default":"","type":"string","description":"If present and non-empty, will assign the new name to the model.  This will not change the UUID, just the `name` field that show up in listing models and assigning tags to detection boxes"},"new_uuid":{"example":false,"default":false,"type":"boolean","description":"If true, will assign a new UUID, effectively copying the model."}}},"ModelSummary":{"properties":{"image":{"example":"models/53255aee-f032-4df1-a61e-1502f1df33d4/image.jpg","type":"string","description":"image description (dataurl or image relative to vmx_dir)"},"history":{"items":{"type":"string"},"type":"array","description":"The name of the pretrained file used to generate the model. Will be an array of the individual models if model is a bundle."},"num_pos":{"type":"integer","description":"The number of positive examples in the model"},"num_neg":{"type":"integer","description":"The number of negative examples in the model"},"size":{"items":{"type":"integer"},"type":"array","description":"The size of the model"},"uuid":{"example":"17b86476-d430-4ecb-8185-aff17c18321c","type":"string","description":"The unique identifier for the model. Model bundles (collections of models) do not have hyphens in the UUID, and individual models have UUIDs in standard 36 character format"},"name":{"example":"tom's hand","type":"string","description":"A human readable model name"},"version":{"type":"string","description":"The version of VMX which generated this model"},"start_time":{"type":"string","description":"Model creation time"},"end_time":{"type":"string","description":"Last image/datapoint time"},"compiled":{"type":"boolean","description":"Whether the model is compiled or not"},"meta":{"type":"string","description":"Extra meta information about the model. Bundles will use comma separated names of individual models for the meta tag."}}},"Change":{"required":["id","class_label"],"properties":{"image":{"type":"string"},"class_label":{"type":"integer","description":"Should be -1 for negative, +1 for postive, and 0 for remove_me"},"time":{"type":"string","description":"Time associated with datapoint"},"score":{"type":"number"},"data":{"items":{"type":"number"},"type":"array"},"id":{"type":"integer","description":"The unique identifier for the exemplar"}}},"Params":{"properties":{"train_max_positives":{"default":1000,"minimum":1,"type":"integer","description":"The maximum number of positives inside the learned model.  VMX automatically adjust the number of positives (by dropping the least useful examples) when a larger number is reached when using learning mode."},"cell_size":{"default":4,"minimum":2,"type":"integer","description":"The spatial cell size (in pixels) used to analyze the input image.  This is the size of the regions for which statistical computations are performed."},"learn_iterations":{"default":10,"minimum":0,"type":"integer","description":"The number of learning iterations after each successful update while processing images in \"learn mode\"."},"max_image_size":{"default":320,"minimum":0,"type":"integer","description":"The maximum input image size (in number of pixels for either width or height).  You are free to send a larger image, but it will be resized to this size if the input is larger. Resizing maintains the aspect ratio, and makes sure that the maximum dimension is within this limit."},"initialize_max_cells":{"default":10,"minimum":1,"type":"integer","description":"The maximum template dimension (measured in cells) used during initialization. Model sizes are reported as #cells x #cells. This parameter makes sure that you don't get very large cell sizes for model creation. If you decide to create a model with initialize_max_cells set to a small value like 4, you might get models that are 2x4, 4x1, etc.  They will be really fast, but much coarser than your typical 8x10 models."},"crop_radius":{"default":80,"type":"integer","description":"The number of pixels around the object of interest to be used in crop mode.  This greatly improves the speed of the detector as fewer regions need to be analyzed. NOTE: this is only used inside the VMX GUI (aka vmxAppBuilder) but stored inside VMX as a convenience."},"max_windows":{"default":100,"minimum":0,"type":"integer","description":"The maximum number of raw detection windows to consider before applying non-maximum suppression.  The final number of detections will always be smaller than max_windows as non-maximum suppression will likely remove some.  The detector becomes really fast for max_windows=0, but it has better performance for large max_windows values."},"learn_threshold":{"default":0,"type":"number","description":"Object detections scoring above this threshold will be considered as positives while in `learn mode`. At most `learn_max_positives` will be treated as positives."},"train_max_negatives":{"default":2000,"minimum":1,"type":"integer","description":"The maximum number of positives inside the learned model.  VMX automatically adjust the number of positives (by dropping the least useful examples) when a larger number is reached when using learning mode."},"jpeg_quality":{"default":1,"type":"number","description":"The JPEG Quality factor controls the size (in MB) of the image but creates compression artifacts. Note: this is only used inside the VMX GUI (aka vmxAppBuilder) but stored inside the model as a convenience."},"display_threshold":{"default":0,"type":"number","description":"When using process_image, drop all detections below this threshold. Mac Only: Objects scoring above this threshold will be rendered on the screen when config.display_images is enabled."},"initialize_add_flip":{"default":false,"type":"boolean","description":"If enabled, model creation will add left-right flips of positives to generate 2X training data, then select the best of each flip."},"detect_add_flip":{"default":false,"type":"boolean","description":"If enabled, will perform detection on left-right flip of input image. Detection then takes twice as long, but only one image needs to be sent to the server."},"learn_max_positives":{"default":1,"minimum":0,"type":"integer","description":"The maximum number of positives which can be extracted from a single image during one step of `learn_mode`.  NOTE that to be considered a positive, then score must be above learn_threshold. You can make the detector treat everything as negatives by setting learn_max_positives to 0, and the learn_threshold to a really low value like -1.  You can make the detector treat all detections above 0 as positives by setting learn_max_positives to something large like 100 and the learn_threshold to 0.  NOTE: If you feed VMX an image with many true positives but learn_max_positives is set to 1, then only the highest scoring detection will be treated as a positive and the remaining detections as negatives."},"levels_per_octave":{"maximum":20,"default":10,"minimum":1,"type":"integer","description":"The levels per octave parameters describes how many different levels we use for object detection.  An octave is a halving of the original image, so 10 levels per octave means we will be looking at 10 different images sizes betwen the original and the halved image. Must be between 1 and 20. Lower will make detection faster, but be careful for scale-dependent blind spots."},"detect_max_overlap":{"maximum":1,"default":0.3,"minimum":0.0,"type":"number","description":"The non-maximum suppression threshold which will remove redundant (highly-overlapping windows).  This number ranges from [0,1] and 0 will not allow any returned detectections to overlap, while a 1.0 will keep all detection windows."},"learn_mode":{"default":false,"type":"boolean","description":"If enabled, go into learn mode."}}},"Object":{"required":["name","bb"],"properties":{"class_label":{"type":"integer","description":"optional class_label used to denote positives (+1), negatives (-1), or remove example (0)"},"score":{"type":"number","description":"optional score associated with example"},"data":{"items":{"type":"number"},"type":"array","description":"Extra data stored with the example"},"bb":{"items":{"type":"number"},"type":"array","description":"The object's bounding box (4 numbers)"},"name":{"example":"left_hand","type":"string","description":"The object's human readable name"},"id":{"type":"integer","description":"optional id used to index examples when using edit_model"}}},"EditModelInput":{"required":["changes","settings"],"properties":{"changes":{"items":{"$ref":"#/definitions/Change"},"type":"array"},"settings":{"$ref":"#/definitions/Settings"}}}},"paths":{"/process_image":{"post":{"summary":"Process Image by applying current model.","responses":{"400":{"description":"Cannot process image"},"200":{"schema":{"properties":{"data":{"properties":{"objects":{"items":{"$ref":"#/definitions/Object"},"type":"array"},"model":{"$ref":"#/definitions/ModelSummary"}}}}},"description":"OK"}},"parameters":[{"required":true,"schema":{"$ref":"#/definitions/ProcessImageInput"},"in":"body","name":"body","description":"Process Image Payload"}],"description":"Process Image by applying current model. Even though the input must be an array of images, for detection and learning is only performed on the first image. Allows the model to grow in size by enabling `learning_mode`. Will not allow `learning_mode` when `config.read_only` is set to `true`.","tags":["detection"]}},"/get_params":{"get":{"summary":"Get the detection params","responses":{"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/Params"}}},"description":"OK"}},"description":"Get the detection params","tags":["settings"]}},"/set_config":{"post":{"summary":"Set the configuration object","responses":{"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/Config"}}},"description":"OK"}},"parameters":[{"schema":{"$ref":"#/definitions/Config"},"in":"body","name":"body","description":"Input Data Set"}],"description":"Set the configuration object","tags":["settings"]}},"/edit_model":{"post":{"summary":"Edit model","responses":{"400":{"description":"Cannot edit model"},"200":{"schema":{"properties":{"data":{"properties":{"images":{"items":{"$ref":"#/definitions/Image"},"type":"array"},"objectives":{"$ref":"#/definitions/Objectives"}}}}},"description":"OK"}},"parameters":[{"required":true,"schema":{"$ref":"#/definitions/EditModelInput"},"in":"body","name":"body","description":"Edit Model Payload"}],"description":"Edit/show the positive examples inside the model. Can be used to show image crops of the positives/negatives, swap examples, or remove examples.","tags":["detection"]}},"/session/{sessionId}":{"get":{"summary":"Get session info","responses":{"404":{"description":"Not Found"},"200":{"schema":{"properties":{"data":{"properties":{"id":{"type":"string","description":"The id of the removed session"}}}}},"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"tags":["session management"]},"delete":{"summary":"Delete current session from VMX","responses":{"404":{"description":"Session id not found"},"200":{"description":"OK"}},"parameters":[{"required":true,"in":"path","name":"sessionId","type":"string","description":"ID of the session"}],"tags":["session management"]}},"/save_model":{"post":{"summary":"Save currently loaded model","responses":{"400":{"description":"Problem saving model"},"200":{"schema":{"properties":{"data":{"properties":{"model":{"$ref":"#/definitions/ModelSummary"},"compiled_MB":{"type":"number","description":"The size of the compiled model in Megabytes"},"full_MB":{"type":"number","description":"The size of the full model in Megabytes"}}}}},"description":"OK"}},"parameters":[{"required":true,"schema":{"$ref":"#/definitions/SaveModelInput"},"in":"body","name":"body","description":"Information about the saved model"}],"description":"Save the currently loaded model into the `${VMX_DIR}` directory. Allows for renaming the model as well as generating a new UUID for the saved model. If the currently loaded model is a bundle, then a new UUID cannot be generated since bundle UUIDs are determined from the component UUIDs. Will not allow save operation when `config.read_only` is set to `true`.","tags":["model_library"]}},"/session":{"post":{"summary":"Create New Session","responses":{"400":{"schema":{"properties":{"error":{"type":"string","description":"A description of the error"}}},"description":"Cannot create session (id contains   illegal characters)"},"200":{"schema":{"properties":{"data":{"items":{"$ref":"#/definitions/ModelSummary"},"type":"array"}}},"description":"OK"}},"parameters":[{"schema":{"$ref":"#/definitions/CreateSessionInput"},"in":"body","name":"body","description":"The new id"}],"description":"Create a new session. You can specify an empty json payload to get a randomly generated session id, or you can provide the session id you want via the `id` field.","tags":["session management"]},"get":{"summary":"List sessions","responses":{"400":{"description":"Problem Listing Model(s)"},"200":{"schema":{"properties":{"data":{"items":{"$ref":"#/definitions/SessionSummary"},"type":"array"}}},"description":"OK"}},"description":"Lists the active VMXworker sessions which are registered by VMX","tags":["session management"]}},"/get_config":{"get":{"summary":"Get the configuration object","responses":{"200":{"schema":{"properties":{"data":{"$ref":"#/definitions/Config"}}},"description":"OK"}},"description":"Get the configuration object","tags":["settings"]}},"/exit":{"post":{"summary":"Exit session","responses":{"400":{"description":"Cannot shutdown (`config.read_only` is `true`)"},"200":{"description":"OK"}},"description":"Shut down the session. Be warned that you **must save your model** if you made edits and don't want to lose changes to your model.","tags":["settings"]}},"/create_model":{"post":{"summary":"Create a new model","responses":{"400":{"description":"Unable to create model. Either `config.read_only` is set to `false` (see set_config) or there was a problem with your payload."},"200":{"schema":{"properties":{"data":{"properties":{"objectives":{"$ref":"#/definitions/Objectives"},"model":{"$ref":"#/definitions/ModelSummary"}}}}},"description":"OK"}},"parameters":[{"required":true,"schema":{"$ref":"#/definitions/CreateModelInput"},"in":"body","name":"body","description":"Model Creation payload"}],"description":"Create a new model given a dataset, a model name, a pretrained file, and detection/creation parameters.\n\n1.) Will look for the pretrained file inside the `data` directory specified in `config.json`,\n\n2.) If not present, will look for the pretrained file in the `/VMXdata/` directory (and copy it over to your `data` directory)\n\n3.) Will download the file from `https://files.vision.ai/vmx/pretrained/` (as long as `config.allow_urls` is set to true) into your `data` directory.\nVMXserver comes with two pretrained files. To get a listing of available pretrained files, run:\n`curl https://files.vision.ai/vmx/pretrained/MD5SUMS.json`\n","tags":["detection"]}}}}